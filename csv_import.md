---
title: "CSV Import"
date: 2023-02-01T10:00:00+01:00
draft: false
weight: 1
---
In addition to data import via the REST API, streams can also be imported in CSV format, if you are running the Lambda Eninge locally, that is without docker. The CSV import is started from the command line and imports events into ChronicleDB according to a predefined configuration. The import is started from the command line with the configuration file as the only argument:
```
java -cp $CLASSPATH en.umr.lambda.rest.loading.CSVLoader $CSV_CONFIG
```

In the folder `lambda-engine/lambda-rest/examples` you will find some examples of the configuration files. All settings are described in detail below.

The CSV configuration is a simple JSON file with the following parameters:

| Name | Type | Description | Example |
| - | - | - | - |
| `path` | `String` | Full path to the CSV file. | ``home/data/data.csv``
| `separator` | `character` | column separator within the CSV file. | `";"` |
| `ignoreFirstRow` | `boolean` | Indicator if the first line of the file should be ignored (e.g., header information). | `true` |
| `skipOnError` | `boolean` | Indicator whether the import should be continued (`true`) or aborted (`false`) in case of errors. If the import is continued, the incorrect lines are skipped. | `true` |
| `inputColumns` | `Array<String>` | Naming the columns of the CSV file. | `["X", "Y"]`
| `streamName` | `String` | Name under which the stream is stored. | ``Points``
| `timestamp` | `Object` | Description of the timestamp column (details in the following lines). | N/A |
| `timestamp.column` | `String` | Name of the column representing the timestamp. This name must match a column name of the `inputColumns` parameter. | `"TIME"`
| `timestamp.type` | `String` | Format of the timestamp. For details, see next section. | ``UNIX``
| `timestamp.timestampPattern` | `String` | Format string for parsing timestamps in the format `STRING`. Details about the format string can be found [here](https://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html). | `"yyyy-MM-dd'T'HH:mm:ss.SSSXXX"`
| `Schema` | `Array<Object>` | Describes the schema of the stream. The array consists of attribute objects, each of which contains at least the name of the attribute and the datatype. Details about the schema definition can be found [here]({{< ref "cdb_rest#create-stream" >}}) . Note that the attribute names must either match the columns of the `inputColumns` parameter, or be generated by a **transformation** (next line).  | `[ { "name": "X", "type": "DOUBLE" }, { "name": "Y", "type": "DOUBLE" } ]`|
| `transformations` | `Array<Object>` | Transformations to be applied to the input columns. An attribute of the schema is generated from any number of input columns. | see [Transformations](#transformations) |

## Timestamps ##
The following formats are supported for timestamps (`timestamp.type` parameter)
- **UNIX**: Unix timestamp in milliseconds (column must contain an integer value)
- **UNIX_S**: Unix timestamp in seconds (column must contain an integer value)
- **STRING**: Date string according to configured format (e.g. "2020-04-20T10:00:00.000")

## Transformations ##
Transformations generate the value for a schema attribute from one or more input columns. The general structure of a transformation in the configuration file is as follows:
```
{
  "type": String; name of the transformation to be applied
  "attribute": String; name of the schema attribute
  "inputColumns": Array<String>; The input columns of the transformation
}
```
The following transformations are currently available:

### Point ###
These transformation converts two numerical input columns into a 2D point geometry. The first input column is used for the X coordinate, the second for the Y coordinate.

**Example**:
```JSON
{
  "type": "point",
  "attribute": "position",
  "inputColumns": [ "X", "Y" ]
}
```

## Complete example ##
The following example imports a stream consisting of temperature measurements and the corresponding sensor position and ID. The timestamp is assumed in millisecond Unix format and the position column is generated by a "point" transformation.
```JSON
{
	"path": "csv/temperatures.csv",
	"separator": ";",
	"ignoreFirstRow": true,
	"skipOnError": true,
	"inputColumns": [
		"ID",
		"LON",
		"LAT",
		"TEMP",
		"TIME"
	],
	"streamName": "Temperatures",
	"timestamp": {
		"column": "TIME",
		"type": "UNIX"
	},
	"transformations": [
		{
			"type": "point",
			"attribute": "POS",
			"inputColumns": [
				"lon",
				"lat"
			]
		}
	],
	"schema": [
		{
			"name": "ID",
			"type": "STRING"
		},
		{
			"name": "POS",
			"type": "GEOMETRY",
			"properties": {
				"index": "true"
			}
		},
		{
			"name": "Temp",
			"type": "DOUBLE"
		}
	]
}
```
The head of the associated CSV file looks like this:
```
ID; LON; LAT; TEMP; TIME
1; 8.811080; 50.809435; 25.3; 1587376800
```
For this example, spaces have been inserted for readability. These are not necessarily necessary.